{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28455259",
   "metadata": {},
   "source": [
    "# Getting the Embedding Sequences \n",
    "For the following models:\n",
    "1) NLP Baseline\n",
    "2) KG Baseline \n",
    "3) STonKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779bcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from stonkgs.constants import (\n",
    "    CELL_LINE_DIR,\n",
    "    CELL_TYPE_DIR,\n",
    "    EMBEDDINGS_PATH,\n",
    "    DISEASE_DIR,\n",
    "    LOCATION_DIR,\n",
    "    MISC_DIR,\n",
    "    NLP_MODEL_TYPE,\n",
    "    ORGAN_DIR,\n",
    "    PRETRAINED_STONKGS_DUMMY_PATH,\n",
    "    RANDOM_WALKS_PATH,\n",
    "    SPECIES_DIR,\n",
    "    VISUALIZATIONS_DIR,\n",
    ")\n",
    "from stonkgs.models.kg_baseline_model import _prepare_df, INDRAEntityDataset\n",
    "from stonkgs.models.nlp_baseline_model import INDRAEvidenceDataset\n",
    "from stonkgs.models.stonkgs_model import STonKGsForPreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4344eb",
   "metadata": {},
   "source": [
    "Record details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a508968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbalabin\n",
      "3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "Thu Jul  1 13:13:41 2021\n"
     ]
    }
   ],
   "source": [
    "print(getpass.getuser())\n",
    "print(sys.version)\n",
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bab1ae",
   "metadata": {},
   "source": [
    "## 0. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1380ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stonkgs_data(unprocessed_df):\n",
    "    sep_id = 102\n",
    "    kg_name_to_idx = {key: i for i, key in enumerate(embeddings_dict.keys())}\n",
    "    \n",
    "    # Convert random walk sequences to list of numeric indices\n",
    "    random_walk_idx_dict = {k: [kg_name_to_idx[node] for node in v] for k, v in random_walks_dict.items()}\n",
    "    \n",
    "    # Get the length of the text or entity embedding sequences (2 random walks + 2 = entity embedding sequence length)\n",
    "    random_walk_length = len(next(iter(random_walk_idx_dict.values())))\n",
    "    half_length = random_walk_length * 2 + 2\n",
    "    \n",
    "    # Initialize the preprocessed data\n",
    "    fine_tuning_preprocessed = []\n",
    "\n",
    "    # Log progress with a progress bar\n",
    "    for _, row in tqdm(\n",
    "        unprocessed_df.iterrows(),\n",
    "        total=unprocessed_df.shape[0],\n",
    "        desc='Preprocessing the fine-tuning dataset',\n",
    "    ):\n",
    "        # 1. \"Token type IDs\": 0 for text tokens, 1 for entity tokens\n",
    "        token_type_ids = [0] * half_length + [1] * half_length\n",
    "\n",
    "        # 2. Tokenization for getting the input ids and attention masks for the text\n",
    "        # Use encode_plus to also get the attention mask (\"padding\" mask)\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            row['evidence'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=half_length,\n",
    "        )\n",
    "        text_token_ids = encoded_text['input_ids']\n",
    "        text_attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "        # 3. Get the random walks sequence and the node indices, add the SEP (usually with id=102) in between\n",
    "        # Use a sequence of UNK tokens if the node is not contained in the dictionary of the nodes from pre-training\n",
    "        random_w_source = random_walk_idx_dict[\n",
    "            row['source']\n",
    "        ] if row['source'] in random_walk_idx_dict.keys() else [unk_id] * random_walk_length\n",
    "        random_w_target = random_walk_idx_dict[\n",
    "            row['target']\n",
    "        ] if row['target'] in random_walk_idx_dict.keys() else [unk_id] * random_walk_length\n",
    "        random_w_ids = random_w_source + [sep_id] + random_w_target + [sep_id]\n",
    "\n",
    "        # 4. Total attention mask (attention mask is all 1 for the entity sequence)\n",
    "        attention_mask = text_attention_mask + [1] * half_length\n",
    "\n",
    "        # 5. Total input_ids = half text ids + half entity ids\n",
    "        input_ids = text_token_ids + random_w_ids\n",
    "\n",
    "        # Add all the features to the preprocessed data\n",
    "        fine_tuning_preprocessed.append({\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,  # Remove the MLM, ELM and NSP labels since it's not needed anymore\n",
    "        })\n",
    "\n",
    "    # Put the preprocessed data into a dataframe\n",
    "    fine_tuning_preprocessed_df = pd.DataFrame(fine_tuning_preprocessed)\n",
    "\n",
    "    return fine_tuning_preprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010ec8f",
   "metadata": {},
   "source": [
    "## 1. Load some example sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4e3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dir = SPECIES_DIR\n",
    "number_unique_tags = 3\n",
    "dataset_version = \"species_no_duplicates.tsv\"\n",
    "number_entries = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3057488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_specific_dataset = pd.read_csv(os.path.join(task_dir, dataset_version), sep=\"\\t\", index_col=None)\n",
    "if \"Unnamed: 0\" in task_specific_dataset.columns.values:\n",
    "    task_specific_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8ef79",
   "metadata": {},
   "source": [
    "Filter out unseen nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c761363",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = _prepare_df(EMBEDDINGS_PATH)\n",
    "random_walks_dict = _prepare_df(RANDOM_WALKS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ba1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_specific_dataset = task_specific_dataset[\n",
    "    task_specific_dataset['source'].isin(embeddings_dict.keys()) & task_specific_dataset['target'].isin(embeddings_dict.keys())\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0937db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9606     18633\n",
       "10090     2857\n",
       "10116      275\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_specific_dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8c34b",
   "metadata": {},
   "source": [
    "Sample the present classes equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "362cc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.DataFrame()\n",
    "\n",
    "for cls in np.unique(task_specific_dataset[\"class\"]):\n",
    "    cls_specific_samples = task_specific_dataset[task_specific_dataset['class'] == cls].sample(\n",
    "        n=number_entries//number_unique_tags)\n",
    "    sampled_df = sampled_df.append(cls_specific_samples)\n",
    "    \n",
    "sampled_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40a77e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9606     266\n",
       "10090    266\n",
       "10116    266\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762608e",
   "metadata": {},
   "source": [
    "## 2. Load all three models \n",
    "1) NLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0db1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_baseline = BertModel.from_pretrained(NLP_MODEL_TYPE)\n",
    "tokenizer = BertTokenizer.from_pretrained(NLP_MODEL_TYPE, model_max_length=512)\n",
    "labels = sampled_df[\"class\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90a78cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3622,  0.0237, -0.3031,  ..., -0.2709,  0.2806, -0.0564],\n",
       "         [ 0.1962, -0.0894,  0.1676,  ...,  0.1158,  0.2761, -0.2423],\n",
       "         [ 0.4463, -0.1143,  0.1978,  ...,  0.3631,  0.5647, -0.0344],\n",
       "         ...,\n",
       "         [ 0.0092,  0.2662, -0.1773,  ...,  0.1612,  0.2934,  0.2623],\n",
       "         [ 0.3508,  0.0314, -0.0435,  ...,  0.3190,  0.2344,  0.1220],\n",
       "         [ 0.6748, -0.2057,  0.3180,  ..., -0.6108, -0.0396, -0.7527]],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor(9606))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence = tokenizer(sampled_df.iloc[0][\"evidence\"], return_tensors=\"pt\", padding='max_length', truncation=True)\n",
    "dummy_nlp_example = (nlp_baseline(**evidence, output_hidden_states=True).last_hidden_state[0], torch.tensor(labels[0]))\n",
    "print(dummy_nlp_example[0].shape)\n",
    "dummy_nlp_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239d7e2",
   "metadata": {},
   "source": [
    "2) KG Baseline (embedding dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a2e05",
   "metadata": {},
   "source": [
    "Since it's based on static embeddings, we only need the \"INDRAEntityDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553b86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_baseline = INDRAEntityDataset(\n",
    "    embeddings_dict,\n",
    "    random_walks_dict,\n",
    "    sampled_df[\"source\"],\n",
    "    sampled_df[\"target\"],\n",
    "    sampled_df[\"class\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fb5a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([254, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0353,  0.0467, -0.0145,  ..., -0.0841, -0.0041, -0.0330],\n",
       "         [ 0.2181, -0.9316, -0.0855,  ...,  0.4753, -0.5085, -0.0165],\n",
       "         [-0.0089, -0.0398,  0.2235,  ...,  0.8814, -0.5135, -0.6484],\n",
       "         ...,\n",
       "         [-0.0089, -0.0398,  0.2235,  ...,  0.8814, -0.5135, -0.6484],\n",
       "         [ 0.1518,  0.2211,  0.3233,  ..., -0.0662,  0.5883,  0.0953],\n",
       "         [-0.3169,  0.0883,  0.3486,  ...,  0.1628, -0.3894, -0.1904]]),\n",
       " tensor(9606))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_kg_example = kg_baseline[0]\n",
    "print(dummy_kg_example[0].shape)\n",
    "dummy_kg_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad18e61",
   "metadata": {},
   "source": [
    "3) STonKGs (LARGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea04d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "stonkgs = STonKGsForPreTraining.from_pretrained(\n",
    "    pretrained_model_name_or_path=PRETRAINED_STONKGS_DUMMY_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d0b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing the fine-tuning dataset: 100%|██████████| 798/798 [00:01<00:00, 794.03it/s] \n"
     ]
    }
   ],
   "source": [
    "stonkgs_data = preprocess_stonkgs_data(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d249ebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2761, -0.2027,  0.7588,  ..., -0.0876,  0.6474,  0.7084],\n",
       "         [-0.5997,  0.2369,  0.6981,  ...,  0.8298,  0.0673,  0.3779],\n",
       "         [-0.4040,  0.4752,  1.0936,  ..., -0.1941, -0.5627,  1.1466],\n",
       "         ...,\n",
       "         [-0.8811,  0.7375,  0.1416,  ...,  1.6385, -0.0081, -0.2853],\n",
       "         [ 0.1901,  0.8254,  0.1284,  ...,  0.8028, -1.2105, -1.4304],\n",
       "         [-1.7002,  0.2221,  0.2442,  ..., -0.7222, -0.6268,  1.1990]],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor(9606))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entry = {key: torch.tensor([value]) for key, value in dict(stonkgs_data.iloc[0]).items()}\n",
    "dummy_stonkgs_example = (stonkgs(**data_entry, return_dict=True).hidden_states[0], torch.tensor(labels[0]))\n",
    "print(dummy_stonkgs_example[0].shape)\n",
    "dummy_stonkgs_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effcacd4",
   "metadata": {},
   "source": [
    "## 3. Get the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a7fd3",
   "metadata": {},
   "source": [
    "1. NLP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "983ae6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_embeddings(list_of_indices):\n",
    "    \"\"\"Returns a list of (embedding_sequence, label) pairs.\"\"\"\n",
    "    all_embed_sequences = []\n",
    "    \n",
    "    for idx in list_of_indices:\n",
    "        nlp_evidence = tokenizer(sampled_df.iloc[idx][\"evidence\"], return_tensors=\"pt\", padding='max_length', truncation=True)\n",
    "        nlp_hidden_states = (nlp_baseline(**nlp_evidence, output_hidden_states=True).last_hidden_state[0],\n",
    "                             torch.tensor(sampled_df.iloc[idx][\"class\"]))\n",
    "        all_embed_sequences.append(nlp_hidden_states)\n",
    "        \n",
    "    return all_embed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4de22f",
   "metadata": {},
   "source": [
    "2. KG embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "857b4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kg_embeddings(list_of_indices):\n",
    "    \"\"\"Returns a list of (embedding_sequence, label) pairs.\"\"\"\n",
    "    all_embed_sequences = []\n",
    "    \n",
    "    for idx in list_of_indices:\n",
    "        all_embed_sequences.append(kg_baseline[idx])\n",
    "        \n",
    "    return all_embed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637c0cc",
   "metadata": {},
   "source": [
    "3. STonKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80eee495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stonkgs_embeddings(list_of_indices):\n",
    "    \"\"\"Returns a list of (embedding_sequence, label) pairs.\"\"\"\n",
    "    all_embed_sequences = []\n",
    "    \n",
    "    for idx in list_of_indices:\n",
    "        data_entry = {key: torch.tensor([value]) for key, value in dict(stonkgs_data.iloc[idx]).items()}\n",
    "        stonkgs_hidden_states = (stonkgs(**data_entry, return_dict=True).hidden_states[0],\n",
    "                                 torch.tensor(sampled_df.iloc[idx][\"class\"]))\n",
    "        all_embed_sequences.append(stonkgs_hidden_states)\n",
    "        \n",
    "    return all_embed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c475b",
   "metadata": {},
   "source": [
    "Testing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0a7e421e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 0.0272,  0.0478, -0.0016,  ..., -0.0485,  0.0049, -0.0204],\n",
       "          [ 0.2156,  0.3641, -0.0936,  ..., -0.0673, -0.5435, -0.2532],\n",
       "          [ 0.4665,  0.1521,  0.0888,  ...,  0.6257, -0.1580, -0.1126],\n",
       "          ...,\n",
       "          [ 0.1234,  0.1534, -0.1528,  ..., -0.3529, -0.1285,  0.0032],\n",
       "          [-0.3890,  0.3860,  0.3015,  ..., -0.3013,  0.1033, -0.1343],\n",
       "          [-0.9419, -1.2984,  0.9635,  ...,  0.3786, -0.6852,  0.2591]]),\n",
       "  tensor(9606)),\n",
       " (tensor([[ 1.1285e-02,  6.1332e-02,  5.4512e-04,  ..., -7.6015e-02,\n",
       "           -1.5385e-03, -3.7382e-02],\n",
       "          [-3.0418e-01,  8.4933e-02,  5.8552e-02,  ..., -5.3119e-01,\n",
       "            1.6921e-01,  3.8191e-02],\n",
       "          [-2.8218e-01, -2.7288e-01,  1.7001e-01,  ...,  1.4877e-01,\n",
       "           -2.5559e-02, -9.1580e-02],\n",
       "          ...,\n",
       "          [-6.3383e-01, -1.7323e+00,  6.2708e-01,  ...,  7.5040e-01,\n",
       "           -5.1296e-01, -1.4195e-02],\n",
       "          [-1.3717e-01,  3.3589e-01,  4.2335e-01,  ...,  9.9479e-01,\n",
       "            7.6927e-01, -5.9935e-01],\n",
       "          [-7.2881e-01, -1.1366e+00,  1.0765e-01,  ...,  2.8577e-01,\n",
       "           -1.2398e-01,  3.9067e-01]]),\n",
       "  tensor(9606)),\n",
       " (tensor([[ 0.0089,  0.0232,  0.0141,  ..., -0.0378, -0.0051, -0.0332],\n",
       "          [ 0.6358, -0.7468,  0.3311,  ...,  0.6860, -0.8179, -0.1930],\n",
       "          [-0.0147,  0.0847, -0.2348,  ...,  0.0229, -0.3867, -0.2788],\n",
       "          ...,\n",
       "          [ 0.5971, -0.4542,  0.2226,  ...,  0.3240,  0.0217,  0.1985],\n",
       "          [ 0.4795, -0.1591,  0.4356,  ...,  0.3503,  0.0405,  0.6409],\n",
       "          [ 0.0110, -0.4472,  0.6590,  ...,  0.8645,  0.0070, -1.0273]]),\n",
       "  tensor(10116))]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nlp_embeddings([1,5,15])\n",
    "get_kg_embeddings([105,150,400])\n",
    "get_kg_embeddings([50,20,600])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
