{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28455259",
   "metadata": {},
   "source": [
    "# Getting the Embedding Sequences \n",
    "For the following models:\n",
    "1) NLP Baseline\n",
    "2) KG Baseline \n",
    "3) STonKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779bcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import torch\n",
    "import umap\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from stonkgs.constants import (\n",
    "    CELL_LINE_DIR,\n",
    "    CELL_TYPE_DIR,\n",
    "    EMBEDDINGS_PATH,\n",
    "    DISEASE_DIR,\n",
    "    LOCATION_DIR,\n",
    "    MISC_DIR,\n",
    "    NLP_MODEL_TYPE,\n",
    "    ORGAN_DIR,\n",
    "    PRETRAINED_STONKGS_DUMMY_PATH,\n",
    "    RANDOM_WALKS_PATH,\n",
    "    SPECIES_DIR,\n",
    "    VISUALIZATIONS_DIR,\n",
    ")\n",
    "from stonkgs.models.kg_baseline_model import _prepare_df, INDRAEntityDataset\n",
    "from stonkgs.models.nlp_baseline_model import INDRAEvidenceDataset\n",
    "from stonkgs.models.stonkgs_model import STonKGsForPreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4344eb",
   "metadata": {},
   "source": [
    "Record details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a508968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbalabin\n",
      "3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "Fri Jul  2 11:31:51 2021\n"
     ]
    }
   ],
   "source": [
    "print(getpass.getuser())\n",
    "print(sys.version)\n",
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bab1ae",
   "metadata": {},
   "source": [
    "## 0. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1380ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stonkgs_data(unprocessed_df):\n",
    "    sep_id = 102\n",
    "    kg_name_to_idx = {key: i for i, key in enumerate(embeddings_dict.keys())}\n",
    "    \n",
    "    # Convert random walk sequences to list of numeric indices\n",
    "    random_walk_idx_dict = {k: [kg_name_to_idx[node] for node in v] for k, v in random_walks_dict.items()}\n",
    "    \n",
    "    # Get the length of the text or entity embedding sequences (2 random walks + 2 = entity embedding sequence length)\n",
    "    random_walk_length = len(next(iter(random_walk_idx_dict.values())))\n",
    "    half_length = random_walk_length * 2 + 2\n",
    "    \n",
    "    # Initialize the preprocessed data\n",
    "    fine_tuning_preprocessed = []\n",
    "\n",
    "    # Log progress with a progress bar\n",
    "    for _, row in tqdm(\n",
    "        unprocessed_df.iterrows(),\n",
    "        total=unprocessed_df.shape[0],\n",
    "        desc='Preprocessing the fine-tuning dataset',\n",
    "    ):\n",
    "        # 1. \"Token type IDs\": 0 for text tokens, 1 for entity tokens\n",
    "        token_type_ids = [0] * half_length + [1] * half_length\n",
    "\n",
    "        # 2. Tokenization for getting the input ids and attention masks for the text\n",
    "        # Use encode_plus to also get the attention mask (\"padding\" mask)\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            row['evidence'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=half_length,\n",
    "        )\n",
    "        text_token_ids = encoded_text['input_ids']\n",
    "        text_attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "        # 3. Get the random walks sequence and the node indices, add the SEP (usually with id=102) in between\n",
    "        # Use a sequence of UNK tokens if the node is not contained in the dictionary of the nodes from pre-training\n",
    "        random_w_source = random_walk_idx_dict[\n",
    "            row['source']\n",
    "        ] if row['source'] in random_walk_idx_dict.keys() else [unk_id] * random_walk_length\n",
    "        random_w_target = random_walk_idx_dict[\n",
    "            row['target']\n",
    "        ] if row['target'] in random_walk_idx_dict.keys() else [unk_id] * random_walk_length\n",
    "        random_w_ids = random_w_source + [sep_id] + random_w_target + [sep_id]\n",
    "\n",
    "        # 4. Total attention mask (attention mask is all 1 for the entity sequence)\n",
    "        attention_mask = text_attention_mask + [1] * half_length\n",
    "\n",
    "        # 5. Total input_ids = half text ids + half entity ids\n",
    "        input_ids = text_token_ids + random_w_ids\n",
    "\n",
    "        # Add all the features to the preprocessed data\n",
    "        fine_tuning_preprocessed.append({\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,  # Remove the MLM, ELM and NSP labels since it's not needed anymore\n",
    "        })\n",
    "\n",
    "    # Put the preprocessed data into a dataframe\n",
    "    fine_tuning_preprocessed_df = pd.DataFrame(fine_tuning_preprocessed)\n",
    "\n",
    "    return fine_tuning_preprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010ec8f",
   "metadata": {},
   "source": [
    "## 1. Load some example sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4e3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dir = SPECIES_DIR\n",
    "number_unique_tags = 3\n",
    "dataset_version = \"species_no_duplicates.tsv\"\n",
    "number_entries = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3057488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_specific_dataset = pd.read_csv(os.path.join(task_dir, dataset_version), sep=\"\\t\", index_col=None)\n",
    "if \"Unnamed: 0\" in task_specific_dataset.columns.values:\n",
    "    task_specific_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8ef79",
   "metadata": {},
   "source": [
    "Filter out unseen nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c761363",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = _prepare_df(EMBEDDINGS_PATH)\n",
    "random_walks_dict = _prepare_df(RANDOM_WALKS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ba1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_specific_dataset = task_specific_dataset[\n",
    "    task_specific_dataset['source'].isin(embeddings_dict.keys()) & task_specific_dataset['target'].isin(embeddings_dict.keys())\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0937db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9606     18633\n",
       "10090     2857\n",
       "10116      275\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_specific_dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8c34b",
   "metadata": {},
   "source": [
    "Sample the present classes equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362cc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.DataFrame()\n",
    "\n",
    "for cls in np.unique(task_specific_dataset[\"class\"]):\n",
    "    cls_specific_samples = task_specific_dataset[task_specific_dataset['class'] == cls].sample(\n",
    "        n=number_entries//number_unique_tags)\n",
    "    sampled_df = sampled_df.append(cls_specific_samples)\n",
    "    \n",
    "sampled_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a77e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9606     266\n",
       "10090    266\n",
       "10116    266\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762608e",
   "metadata": {},
   "source": [
    "## 2. Load all three models \n",
    "1) NLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0db1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_baseline = BertModel.from_pretrained(NLP_MODEL_TYPE)\n",
    "tokenizer = BertTokenizer.from_pretrained(NLP_MODEL_TYPE, model_max_length=512)\n",
    "labels = sampled_df[\"class\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a78cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0516, -0.0117, -0.9619, -0.9606,  0.9807,  0.1207, -0.0949, -0.9607,\n",
       "         -0.0948, -0.0359, -0.8395, -0.2051, -0.9999,  0.8026, -0.0210,  0.0333,\n",
       "          0.9846, -0.0474,  0.9717,  0.0659,  0.0233,  0.9511, -0.0293,  1.0000,\n",
       "          0.0578,  0.0700,  0.0301, -0.9661, -0.0026, -0.0895, -0.0419, -0.9713,\n",
       "          0.9998,  0.8023, -0.0731, -0.0128,  0.0747, -0.1218,  0.9463, -1.0000,\n",
       "         -0.0105, -0.9161, -0.1222, -0.0921,  1.0000, -0.1230,  0.0273,  0.1322,\n",
       "         -0.0319, -0.9620,  0.0723, -0.9997, -0.9993, -0.9608, -0.8467,  0.2483,\n",
       "          0.9755,  0.0596, -0.9983,  0.0961,  0.9726,  0.0426, -0.1675, -0.1576,\n",
       "         -0.1715, -0.0422, -0.9993,  0.1058,  0.0729,  0.0361,  0.0322,  0.0136,\n",
       "         -0.8089, -0.3076, -0.0858,  0.0897,  0.1244,  0.9798, -0.6409, -0.8102,\n",
       "          0.1011,  0.9724,  0.9803, -0.0667, -0.0280,  0.0850, -0.9993,  0.8490,\n",
       "          0.0353, -0.1529,  0.9996, -0.5020, -0.0668, -0.9990, -0.9738, -0.9382,\n",
       "          0.0194,  0.0484,  0.9995,  0.0196, -0.0012,  1.0000,  0.9998, -0.9135,\n",
       "          0.9999,  0.0877,  0.0353, -0.2315,  0.0119,  0.1065,  0.0866, -0.0570,\n",
       "         -0.1205,  0.0359,  1.0000, -0.9962,  0.9611,  0.9818, -0.0537, -0.9751,\n",
       "         -0.0536,  1.0000, -0.5667, -0.0249,  0.0216, -0.0609,  0.0328,  1.0000,\n",
       "          0.0331, -0.1102,  0.0652,  0.4527, -1.0000, -0.9546, -0.0013, -0.7194,\n",
       "          0.8631,  1.0000,  0.9575, -0.1454, -0.9995,  0.0507, -1.0000, -0.0624,\n",
       "          0.6935, -0.0590, -1.0000, -0.0112,  0.0117, -0.2729, -0.0584,  0.1373,\n",
       "          0.0145, -0.9992,  1.0000,  1.0000,  1.0000,  0.0430, -0.0201,  1.0000,\n",
       "         -0.1352,  0.9573,  0.3762, -1.0000, -0.9002,  0.5569,  0.2160, -0.9916,\n",
       "         -0.9190, -0.0271, -0.1040,  0.0547,  0.0508, -0.9997,  0.0496,  0.0608,\n",
       "          0.0451, -0.0502,  0.6268, -0.0941, -0.9994, -0.0381,  0.0868,  0.9988,\n",
       "         -0.7188,  0.0449,  0.8894,  0.1027,  0.0692,  0.1223, -0.0630,  0.4078,\n",
       "          0.9993, -0.0042,  0.1626, -0.1127, -0.9375, -0.0482, -0.9484,  0.0370,\n",
       "         -0.6029, -0.9534,  0.9996,  0.1602, -0.1113,  0.1636,  0.0546,  0.1440,\n",
       "          0.9998,  0.9991,  0.9992,  0.0014, -0.0177, -0.1760,  0.0470, -0.1747,\n",
       "         -0.0489,  0.0447,  0.1564, -0.9441,  0.8735, -0.0648, -0.0360,  0.6961,\n",
       "          0.1017,  0.0601, -0.0349, -0.9921,  0.0025,  0.7853,  0.0222,  1.0000,\n",
       "          0.9803,  0.0360, -0.0078,  0.9509, -0.8953,  0.1200, -0.0219,  0.1112,\n",
       "          0.1053, -0.0420, -0.0402, -1.0000, -0.2134, -0.0898, -0.9994,  0.1618,\n",
       "          0.1576, -0.9999,  0.1419, -0.9739,  0.0037,  0.2110, -1.0000,  1.0000,\n",
       "         -0.8104, -0.4361, -0.0863, -0.9996,  0.0510,  0.9985, -0.0032,  0.0909,\n",
       "         -0.1707,  0.1057,  0.0796,  0.0567, -0.0266, -0.0884,  0.9665, -0.0222,\n",
       "         -0.0310,  0.6778,  0.9877,  0.0806, -0.1265,  0.1079, -0.9684,  0.9324,\n",
       "          0.0541, -0.9995, -0.9829, -0.1178, -0.9667, -0.9913, -0.0530,  0.4842,\n",
       "         -0.0841,  0.7130,  0.0408, -0.0642, -0.1604,  0.0822,  0.0861, -0.0421,\n",
       "         -0.8040, -0.9759, -0.0528,  0.0160, -0.0438, -0.9653,  0.9980, -0.1736,\n",
       "          0.1463,  0.9776,  0.9659,  0.9841, -0.9993,  1.0000, -0.9923,  0.0383,\n",
       "         -0.0087, -1.0000,  0.0371, -0.9730,  0.0547,  0.0104,  0.1003,  0.9999,\n",
       "         -0.0218,  0.0524, -0.1599,  0.1466,  0.1118,  0.0538,  0.9999,  0.9851,\n",
       "          0.8721,  1.0000,  0.0711, -0.0333, -0.9972, -0.0686,  0.0987,  0.1386,\n",
       "         -0.0997, -0.1402,  0.9998,  0.0578, -0.0164, -0.9999,  0.0994,  0.7372,\n",
       "          0.1063,  0.9469, -0.8809, -0.0619,  0.5458, -0.9978, -0.9742,  0.9066,\n",
       "          0.1097,  0.1148,  0.1107, -0.1079,  0.9760,  0.9994,  0.9996,  0.0964,\n",
       "          0.0172, -0.0762,  0.0518, -0.9998, -0.0286, -0.9996, -0.0945, -0.5626,\n",
       "          0.9994, -0.0823,  0.0519, -1.0000, -0.0807, -0.0166, -0.9913,  0.0317,\n",
       "         -1.0000,  0.0420,  0.9996,  0.0317,  1.0000,  0.1204, -0.1311,  0.9824,\n",
       "          0.1270, -0.5565, -0.4359,  0.1517,  0.7124,  0.0444,  0.1960, -0.0666,\n",
       "          0.9986,  0.0569,  0.0137,  0.9816,  0.0238, -0.0445, -0.0276, -0.1364,\n",
       "          0.0648, -0.1724,  0.9999,  0.1169, -0.0724,  0.0173, -0.0387, -0.2161,\n",
       "         -0.0831, -0.1677, -0.0261,  0.1500, -0.1177,  0.0029, -0.0044, -0.9784,\n",
       "          0.1813,  0.9578, -0.9571, -0.0858,  0.9150, -0.0627,  0.9570,  0.9745,\n",
       "          0.9999, -0.9995, -0.9994,  0.9457,  0.9926,  0.6409, -0.0488,  0.0478,\n",
       "         -0.0958, -0.9996,  0.1037, -0.0369, -0.0501,  0.1373,  0.0172, -0.8849,\n",
       "          0.9773,  0.9183,  0.0898,  1.0000, -0.9990, -0.9999,  0.1908, -0.9752,\n",
       "         -0.1270,  0.1092,  0.0775, -0.0892, -0.0082,  0.9579,  0.0239,  0.1080,\n",
       "         -0.0489, -0.0145, -0.1032, -0.9408,  0.9989, -0.0605, -0.1025,  0.5272,\n",
       "          0.9998, -1.0000, -0.9975,  0.8989,  0.0174,  0.0300,  0.6919,  0.0687,\n",
       "          1.0000, -0.9780, -0.8853, -0.0479,  0.0417,  0.1046,  0.0103,  0.9471,\n",
       "         -0.0019, -0.0723, -0.0625, -0.9916,  0.1672, -0.0629, -0.9931, -1.0000,\n",
       "          1.0000,  0.0336, -0.0333, -0.1810, -0.1705,  0.0880,  0.1176,  0.8616,\n",
       "          0.3474,  0.9766, -0.9921, -0.7448,  1.0000,  0.9997,  0.1793, -0.1785,\n",
       "         -1.0000,  0.9971,  0.0883,  0.0215,  0.9229, -0.9778,  0.9705,  0.0105,\n",
       "         -0.0911,  1.0000, -0.6800,  0.0057,  0.9505,  0.8644,  0.7922, -0.0202,\n",
       "          0.0269, -0.0986,  0.0214, -0.0614, -0.2750, -0.9592,  0.0179,  0.0179,\n",
       "         -0.9996,  0.1381,  0.0080,  0.9683,  0.9999,  0.1256,  0.7008,  0.1239,\n",
       "         -0.5259, -0.0960, -0.9992, -0.9775,  0.6868, -0.9867,  0.9190, -0.9995,\n",
       "         -0.9590, -0.9854, -0.1946, -0.9749, -0.9999,  0.0088,  0.0564,  0.0424,\n",
       "         -0.8376, -0.9851,  0.9254,  0.0479, -0.9998, -1.0000,  0.9999,  0.0824,\n",
       "         -0.0167,  0.1220,  0.0589, -0.0526,  0.9999, -0.9880, -0.0239, -0.0124,\n",
       "         -0.9749, -0.5451,  0.0744, -0.0199,  0.9816, -0.0337,  0.0378, -0.0023,\n",
       "         -0.1316, -0.2063,  0.0131,  0.9633,  0.9997,  0.0082,  0.0401,  0.1997,\n",
       "          0.1051,  0.9597,  0.0886, -0.5529,  0.9792, -0.9999,  0.0400,  0.0760,\n",
       "         -0.0148, -0.2029, -0.9797,  0.9764,  0.9995, -0.1038,  0.9613,  0.0211,\n",
       "         -0.0774, -0.4048, -0.1334,  0.9984,  0.0405,  0.9603, -0.0495, -0.0475,\n",
       "          0.6179, -0.9734, -0.9995,  0.2268, -0.0984, -0.0499, -0.9745, -0.0306,\n",
       "          0.9522,  0.0214, -0.0667,  0.9996, -0.9681, -0.0448,  0.6361, -0.6929,\n",
       "         -0.9518, -0.0578, -0.0136,  0.0374,  0.8428, -0.9999,  0.0488, -0.0733,\n",
       "         -0.9999,  0.9971,  0.0717,  0.9955,  0.9699,  0.1643,  0.9997,  0.0234,\n",
       "         -0.1540,  0.1882,  0.1425, -0.9999,  0.0047,  0.1203,  0.1383, -0.1883,\n",
       "          0.0235, -0.0359, -0.9881, -0.8960,  0.2246,  0.5190,  0.0966, -0.1252,\n",
       "          0.1736,  0.0830, -0.0404,  0.1136, -1.0000,  0.9817, -0.3145, -0.2010,\n",
       "         -0.1873,  0.1927, -1.0000, -0.0879,  0.0604,  0.0162, -0.0900, -0.0378,\n",
       "         -0.1644,  0.0978,  0.9979,  0.9797, -0.0655, -0.0394,  0.0187, -0.0991,\n",
       "          0.9997,  0.9716,  0.9715, -0.9627,  0.8754,  0.0731,  0.0549, -0.0434,\n",
       "          0.0353, -0.0885,  1.0000, -0.9607, -0.0049,  0.9694,  0.0591, -0.0236,\n",
       "          0.0289, -0.0426,  0.9891, -1.0000, -0.0821,  0.7534,  0.9646, -0.9573,\n",
       "         -0.0524,  0.9556,  0.0383,  0.1740,  0.0478,  0.9994, -1.0000, -0.0581,\n",
       "          0.9594,  0.0946,  0.9939, -0.4463, -0.0762,  0.0708,  0.9733, -0.2273,\n",
       "          0.0460,  0.9774,  0.9962, -1.0000, -0.9964,  0.8316,  0.9790,  0.1287,\n",
       "         -0.5947,  0.1025, -0.2228,  0.9983,  0.9653, -0.9995,  0.0330, -0.0249,\n",
       "          0.0966, -1.0000, -0.9995, -0.9778,  0.9996, -0.9525,  0.1221,  0.6627,\n",
       "          0.8607,  0.0061,  0.8808,  1.0000, -0.0773,  0.9854,  0.1834,  0.9785,\n",
       "          0.8732,  0.0370,  0.0031,  0.9774,  0.1423, -0.9999, -0.0959, -0.0106,\n",
       "         -0.1059, -0.1163, -0.0095, -0.0634, -0.0747, -0.9745, -0.0227,  0.9628],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor(9606))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence = tokenizer(sampled_df.iloc[0][\"evidence\"], return_tensors=\"pt\", padding='max_length', truncation=True)\n",
    "dummy_nlp_example = (nlp_baseline(**evidence, output_hidden_states=True, return_dict=True).pooler_output[0], torch.tensor(labels[0]))\n",
    "print(dummy_nlp_example[0].shape)\n",
    "dummy_nlp_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239d7e2",
   "metadata": {},
   "source": [
    "2) KG Baseline (embedding dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a2e05",
   "metadata": {},
   "source": [
    "Since it's based on static embeddings, we only need the \"INDRAEntityDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553b86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_baseline = INDRAEntityDataset(\n",
    "    embeddings_dict,\n",
    "    random_walks_dict,\n",
    "    sampled_df[\"source\"],\n",
    "    sampled_df[\"target\"],\n",
    "    sampled_df[\"class\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb5a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1.2293, 1.0236, 1.1940, 1.1248, 1.3703, 1.5178, 1.3103, 1.0333, 1.1640,\n",
       "         0.8238, 1.2085, 1.2224, 1.0132, 1.0950, 1.2097, 1.1800, 1.2709, 1.3301,\n",
       "         0.8403, 1.1180, 0.9705, 0.9043, 1.4194, 1.1620, 1.8903, 1.0841, 1.6645,\n",
       "         0.6901, 1.4775, 0.8453, 0.9264, 0.8676, 1.3635, 0.7040, 0.5950, 0.8344,\n",
       "         1.0458, 1.0762, 0.8174, 1.6167, 1.4221, 1.2033, 1.2731, 1.1344, 1.7208,\n",
       "         1.4036, 1.7233, 1.2920, 1.0149, 1.3701, 0.5808, 0.9727, 1.2350, 0.8186,\n",
       "         1.0659, 1.0553, 1.6057, 1.7285, 1.2958, 1.4424, 1.2029, 1.4429, 1.0703,\n",
       "         0.9583, 1.0092, 0.8927, 1.0301, 1.6472, 1.3931, 1.3301, 1.3097, 1.2086,\n",
       "         1.3953, 1.0689, 1.2527, 1.3271, 1.4885, 1.1854, 1.3332, 0.9092, 1.7597,\n",
       "         1.0955, 1.0021, 1.6596, 1.2740, 1.1206, 1.6186, 1.2661, 1.0492, 0.9483,\n",
       "         1.8316, 0.8491, 1.4526, 1.2925, 1.2920, 0.7024, 1.2879, 1.3619, 1.5463,\n",
       "         1.7380, 1.1124, 0.7886, 0.8572, 1.4648, 0.8843, 0.7579, 0.9341, 1.1778,\n",
       "         1.2215, 0.7408, 1.0231, 1.1645, 1.3517, 0.8759, 1.6811, 1.0941, 1.2291,\n",
       "         1.2884, 1.4404, 0.9853, 1.0512, 1.5368, 1.1855, 1.6798, 1.2592, 1.0179,\n",
       "         1.1545, 1.2378, 0.9432, 1.6203, 1.4559, 0.8870, 1.2917, 2.1383, 1.6811,\n",
       "         0.9007, 1.0024, 1.2788, 1.1432, 1.8125, 1.4103, 1.1089, 1.8349, 1.0660,\n",
       "         1.1936, 0.5916, 1.4117, 0.9046, 1.4999, 2.1265, 1.1248, 0.7214, 0.9603,\n",
       "         1.2587, 1.1009, 1.4051, 1.1901, 0.8252, 1.6105, 1.3028, 1.2046, 1.4107,\n",
       "         1.1300, 1.2357, 1.4163, 1.0828, 1.9220, 1.4512, 1.0470, 0.9316, 1.0414,\n",
       "         1.1316, 1.6355, 1.6837, 1.0858, 1.0726, 1.2887, 1.7649, 1.2439, 1.1501,\n",
       "         0.9477, 1.1994, 1.2028, 1.2765, 0.8333, 1.2925, 0.9515, 1.3818, 1.4192,\n",
       "         0.9844, 0.9540, 1.4845, 0.7962, 0.8656, 1.1965, 1.5324, 0.9763, 0.7619,\n",
       "         1.0972, 1.3277, 1.2931, 0.9004, 1.2031, 0.8020, 1.7139, 1.1014, 1.6589,\n",
       "         1.0130, 1.2924, 1.8830, 1.4024, 1.5940, 1.4280, 0.9987, 0.7380, 1.1657,\n",
       "         0.8520, 0.8278, 1.4338, 0.9331, 1.2353, 1.2424, 1.3632, 1.4456, 1.3830,\n",
       "         1.4018, 1.2119, 0.6548, 0.9762, 1.2898, 1.9603, 1.3156, 1.1972, 1.1949,\n",
       "         0.6580, 1.3529, 0.6719, 1.2405, 1.0775, 0.8264, 0.9474, 1.3018, 1.7118,\n",
       "         0.9460, 0.8953, 1.2523, 1.2092, 1.2953, 1.3375, 1.4969, 0.6737, 1.1176,\n",
       "         1.0429, 0.9049, 1.1043, 1.3786, 0.9876, 1.8992, 0.5124, 1.3448, 1.3318,\n",
       "         0.9459, 0.8836, 0.9477, 1.4751, 1.3689, 1.1268, 1.2473, 0.9574, 0.7217,\n",
       "         1.2875, 1.7853, 1.1819, 0.8349, 0.8366, 1.5069, 0.9460, 0.8425, 1.0468,\n",
       "         1.0369, 1.5396, 1.1212, 0.7515, 0.8893, 0.9961, 1.1121, 1.0192, 1.2899,\n",
       "         1.9876, 2.4668, 0.7528, 1.2671, 0.8486, 0.7995, 1.6330, 1.9344, 0.8219,\n",
       "         1.0396, 1.5675, 1.8643, 0.9620, 1.4654, 1.3393, 1.5349, 1.3501, 0.9598,\n",
       "         1.5519, 1.0090, 1.1996, 1.8663, 0.5762, 0.9046, 0.7836, 0.9442, 1.6186,\n",
       "         0.9863, 1.5878, 0.8767, 0.6591, 1.1508, 1.0019, 1.3686, 2.0952, 0.9625,\n",
       "         0.8603, 1.4922, 1.3245, 1.2570, 1.9500, 1.1450, 1.2294, 1.6292, 1.1171,\n",
       "         0.8371, 0.9521, 1.0935, 1.1024, 0.8793, 1.2286, 1.4391, 1.6161, 1.2424,\n",
       "         1.0042, 0.6498, 1.2600, 1.6835, 1.2615, 1.7253, 0.9789, 0.9665, 1.4125,\n",
       "         1.1764, 1.5234, 1.2105, 0.9329, 1.5137, 1.1301, 1.4343, 0.9910, 0.8577,\n",
       "         1.0423, 1.0008, 1.2049, 1.4582, 1.9035, 1.5366, 0.8513, 0.8919, 0.9492,\n",
       "         1.2062, 0.9851, 1.1632, 1.7093, 1.3761, 1.2986, 1.2160, 0.7003, 1.1690,\n",
       "         1.0332, 1.0910, 1.3722, 0.9208, 1.1611, 0.9026, 1.1070, 0.8495, 1.9804,\n",
       "         1.3051, 1.1580, 0.8588, 0.8460, 0.7132, 0.6962, 0.9926, 1.3340, 1.3542,\n",
       "         0.9900, 1.3471, 1.0599, 1.0534, 0.9752, 0.9565, 1.0791, 0.9112, 0.7123,\n",
       "         0.7899, 1.2179, 1.0899, 1.5486, 1.2127, 0.9606, 1.0075, 1.3705, 0.8962,\n",
       "         1.1864, 0.7341, 0.9508, 1.2314, 1.2231, 0.5971, 1.0805, 0.9138, 1.6307,\n",
       "         0.6752, 1.2814, 0.8779, 1.3944, 3.5165, 1.2051, 1.0354, 1.4100, 1.3570,\n",
       "         1.1384, 0.8093, 1.1131, 2.1660, 0.9124, 1.1220, 1.1840, 1.0810, 1.4059,\n",
       "         0.9807, 1.1017, 0.9163, 0.9447, 1.1854, 1.1136, 0.9527, 1.4989, 1.6468,\n",
       "         0.8328, 0.9733, 1.6173, 1.3562, 0.9308, 1.4795, 1.5745, 1.2115, 1.2674,\n",
       "         1.3649, 1.0489, 0.9460, 1.5924, 0.8006, 1.8301, 1.3158, 1.3272, 1.2518,\n",
       "         0.8483, 1.1985, 1.2937, 1.1363, 0.5764, 1.0059, 1.0200, 1.1676, 1.1648,\n",
       "         1.0365, 0.8483, 1.1191, 0.7694, 1.1905, 0.8586, 1.3308, 1.7057, 0.8494,\n",
       "         0.9250, 1.4104, 1.0929, 4.1383, 1.4663, 0.9970, 1.0525, 1.1616, 0.8663,\n",
       "         2.9170, 1.1386, 1.2411, 0.8642, 0.7722, 1.6723, 1.1374, 1.5177, 1.7006,\n",
       "         1.6714, 2.0180, 3.0427, 1.9638, 1.1538, 1.1344, 1.8257, 1.1796, 1.3024,\n",
       "         1.2480, 1.0959, 0.8691, 1.4213, 1.4906, 1.1241, 1.3250, 1.1010, 1.1886,\n",
       "         0.8235, 1.0141, 0.9678, 0.8026, 0.8310, 1.2439, 1.0179, 0.7203, 1.0032,\n",
       "         0.9201, 1.3907, 1.6493, 1.0659, 0.9362, 1.1613, 1.5278, 1.1721, 1.4897,\n",
       "         0.8597, 1.5134, 1.4985, 0.9401, 1.1394, 0.9025, 1.0121, 0.9706, 0.9022,\n",
       "         1.7639, 0.9919, 1.3086, 1.2509, 1.1958, 0.9160, 1.0340, 1.6449, 0.9150,\n",
       "         1.0379, 1.3689, 1.2016, 0.9241, 0.8477, 1.1630, 1.1701, 1.2113, 1.4947,\n",
       "         0.5661, 1.1477, 1.5445, 0.7778, 1.4275, 0.7647, 1.3941, 0.8399, 1.4778,\n",
       "         0.9335, 0.9722, 0.8900, 1.4689, 1.0320, 1.5522, 1.1556, 1.1947, 1.0521,\n",
       "         0.9735, 1.5590, 0.9789, 1.2287, 1.0433, 1.0800, 1.1720, 1.0004, 0.9660,\n",
       "         1.7382, 1.3393, 1.1734, 0.9118, 1.1714, 0.7410, 0.7630, 1.6954, 0.9946,\n",
       "         1.2454, 1.5710, 1.2678, 0.9343, 1.3822, 0.8413, 1.3623, 1.4989, 0.8028,\n",
       "         1.4744, 1.3390, 0.7138, 1.3256, 1.5469, 1.1485, 0.8393, 1.1942, 1.2540,\n",
       "         0.9827, 1.0375, 1.1738, 1.2434, 1.6558, 1.4168, 0.9081, 1.1746, 1.0928,\n",
       "         1.2624, 1.0467, 0.8907, 1.0129, 1.6333, 1.6213, 0.6759, 0.9481, 1.3952,\n",
       "         1.1429, 1.5668, 1.4439, 1.3199, 1.4174, 1.4691, 1.1151, 1.3250, 1.2536,\n",
       "         1.9409, 1.5179, 0.8773, 1.5793, 1.2544, 0.6794, 1.3927, 1.6666, 1.0987,\n",
       "         1.1694, 1.1121, 1.9394, 1.3409, 1.9481, 1.1651, 0.8755, 1.2014, 1.1980,\n",
       "         1.5963, 1.3538, 0.8930, 1.2631, 1.1660, 1.2019, 0.8696, 1.3747, 1.1284,\n",
       "         1.2737, 1.1805, 1.0609, 1.1503, 1.2196, 2.9847, 0.8734, 0.6974, 0.9393,\n",
       "         1.2716, 1.2223, 1.0889, 0.9424, 0.9326, 0.8219, 1.2075, 1.7598, 1.2833,\n",
       "         1.2326, 1.3321, 1.2565, 1.5515, 1.4341, 1.0318, 1.0038, 0.9962, 1.1677,\n",
       "         1.1029, 1.0047, 0.8853, 0.8910, 1.5857, 1.0196, 2.2357, 1.7263, 1.9813,\n",
       "         1.1426, 1.6894, 0.8779, 1.9732, 1.1390, 0.8813, 0.8167, 0.8045, 1.2204,\n",
       "         1.0567, 1.6267, 1.2049, 1.5059, 1.5082, 1.9023, 1.6027, 1.1439, 1.5972,\n",
       "         0.7992, 2.4677, 1.2601, 1.1142, 1.2541, 2.2021, 1.0768, 1.2324, 0.9035,\n",
       "         1.1991, 1.6254, 2.1656, 0.9371, 1.3515, 1.2082, 1.1226, 1.6690, 0.9872,\n",
       "         1.1030, 0.9713, 1.0127, 1.0952, 1.3809, 1.3211, 0.9692, 1.0684, 1.3032,\n",
       "         1.0622, 1.1772, 0.9474, 1.0133, 1.4812, 0.7281, 0.8639, 1.0794, 1.1480,\n",
       "         2.1196, 1.2473, 0.9517]),\n",
       " tensor(9606))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_kg_example = (torch.max(kg_baseline[0][0], dim=0).values, kg_baseline[0][1])\n",
    "print(dummy_kg_example[0].shape)\n",
    "dummy_kg_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad18e61",
   "metadata": {},
   "source": [
    "3) STonKGs (LARGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea04d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "stonkgs = STonKGsForPreTraining.from_pretrained(\n",
    "    pretrained_model_name_or_path=PRETRAINED_STONKGS_DUMMY_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d0b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing the fine-tuning dataset: 100%|██████████| 798/798 [00:00<00:00, 1136.91it/s]\n"
     ]
    }
   ],
   "source": [
    "stonkgs_data = preprocess_stonkgs_data(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d249ebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1893,  0.0368,  0.1354, -0.9218, -0.0083,  0.1043, -0.9507, -0.1795,\n",
       "          0.9881,  0.1231, -0.8932,  0.1262, -1.0000,  0.9992,  0.8193, -0.2461,\n",
       "          0.1265,  0.2537, -0.9846,  0.4080,  0.1113,  0.4275,  0.3919,  0.3051,\n",
       "         -0.6842,  0.8513, -0.9997, -0.3284, -0.9122, -0.1575, -0.9655, -0.0572,\n",
       "          0.9998, -0.0074,  0.1943, -0.0920,  0.9995,  0.9998,  0.6955,  0.9929,\n",
       "         -0.9966, -0.1195, -0.9285, -0.7006, -0.1586,  0.1327, -0.4811, -0.3151,\n",
       "         -0.9493,  0.0792,  0.9892,  0.3913,  0.9987,  0.0928,  0.2667,  0.8162,\n",
       "          0.0374,  0.1394,  0.3588, -0.1755,  0.1335,  0.2674, -0.6229, -0.0437,\n",
       "          0.1301,  0.2411,  0.1050,  0.9995, -0.2979,  0.9064, -0.2565, -0.9796,\n",
       "         -0.9500, -0.7333, -0.0052, -0.7721, -0.0592, -0.0552,  0.9994, -0.0421,\n",
       "         -0.6122, -0.1663, -0.5688, -0.0700,  0.9960, -0.9965, -0.9714, -0.0526,\n",
       "         -0.2881,  0.9996, -0.4040, -0.8263, -0.0431, -0.9957,  0.0339,  0.9985,\n",
       "         -0.5564, -0.3928, -0.8605,  0.3640, -0.9625, -0.8368,  0.9084,  1.0000,\n",
       "          0.9592, -0.9274,  0.1020,  0.6728, -0.9995, -0.2568,  0.6497,  0.9950,\n",
       "          0.9385, -0.5124,  0.1469,  0.4126, -0.0726, -0.2361, -0.1443,  0.0672,\n",
       "          0.7988,  0.9974,  0.2763,  0.1000,  0.9447,  0.1216, -0.6431, -0.9999,\n",
       "         -0.9764,  0.4523,  0.3016, -0.7430, -0.3109,  0.0501,  0.1807,  0.2719,\n",
       "          0.0929, -0.0637,  0.9983,  0.0253, -0.1743, -0.8037,  0.9688,  0.0504,\n",
       "         -0.4751,  0.1320, -0.4405, -0.9759, -0.3528,  0.3887, -0.9657,  0.2794,\n",
       "          0.6490, -1.0000, -0.0984,  0.3848, -0.5148,  0.1713, -0.9556, -0.9948,\n",
       "         -0.3662,  0.0631,  0.0627,  0.2038,  0.9978, -0.9998,  0.9992,  0.9772,\n",
       "          0.9973, -0.7944, -0.1784,  0.3470,  0.7430, -0.4534, -0.9990, -0.8501,\n",
       "          0.9990, -0.2093,  0.0238, -0.9939, -0.2180,  0.4416, -0.0778,  0.3183,\n",
       "          0.9999, -0.9969, -0.2023, -0.8545,  0.0118, -0.6501,  0.9990,  0.8633,\n",
       "          0.0893, -0.1965,  0.0255, -0.9999, -0.9793,  0.9991, -0.2271, -0.0789,\n",
       "         -0.5744,  0.6358,  0.9732,  0.0013,  0.8105,  0.1077, -0.9955,  0.2681,\n",
       "          0.0862,  0.5198,  0.1328,  0.2249, -0.9870, -0.3128, -0.9997, -0.9848,\n",
       "          0.9995,  0.1919, -0.0369, -0.2984,  0.3013,  0.9383, -0.9854, -0.1055,\n",
       "         -0.9961, -0.9295, -0.2201,  0.0133,  0.8143,  0.0718, -0.0687, -0.0049,\n",
       "         -0.7473,  0.4904, -0.9919, -0.9962, -0.7995, -0.0779,  0.0121, -0.3041,\n",
       "         -0.9982, -0.1986,  0.9999, -0.9882,  0.9986,  0.9900, -0.9504, -0.2068,\n",
       "          0.8573, -1.0000, -0.9591,  0.9447, -0.9998, -0.0134, -0.9347, -0.5608,\n",
       "          0.3341, -0.9290, -0.9959,  0.9550,  0.9683,  0.8066, -0.6149,  0.1409,\n",
       "         -0.0294,  0.9998, -0.9771,  0.9437,  0.4017, -0.1592, -0.1159,  0.3512,\n",
       "         -0.0459, -0.0482,  0.2046,  0.0048,  0.9980,  0.8612,  0.9964,  0.3096,\n",
       "         -0.9203, -0.8806,  0.9993,  0.9854, -0.0548, -0.0159,  0.9552, -0.1459,\n",
       "          0.3694,  0.9966, -0.9998, -0.9928,  0.9909, -0.8537,  0.3014,  0.9609,\n",
       "         -0.2940, -0.9622, -0.9681,  0.2207,  0.2275, -0.5992,  0.3347,  0.8868,\n",
       "         -0.9696,  0.6537,  0.1224, -0.9689, -0.0113, -0.0230,  0.0902, -0.9903,\n",
       "         -0.1799, -0.0224,  0.1187, -0.7266,  0.2552, -0.8489,  0.6603, -0.7421,\n",
       "          1.0000, -0.5567,  0.0901,  0.9345, -0.4210,  0.9323,  0.0990, -0.0399,\n",
       "          0.9778,  0.0149,  0.3681, -0.1952, -0.9480, -0.8575,  0.8726, -0.2801,\n",
       "         -0.3976,  0.0337,  0.0112, -0.0607, -0.9347,  0.2242, -0.8826,  0.9941,\n",
       "         -0.2550,  0.9814, -0.0355, -0.5499, -0.5950,  0.9929,  0.9991, -0.0378,\n",
       "          0.9213, -0.2725, -1.0000, -0.9937,  0.0357, -0.9190,  0.8593, -0.4952,\n",
       "          0.9945,  0.1283, -0.4262,  0.3500, -0.9353,  0.1554,  0.9986, -0.1203,\n",
       "         -0.4830, -0.2102, -0.9923, -0.6585, -0.9999, -0.0085,  0.4149,  0.0746,\n",
       "         -0.1542, -0.0349, -0.6139,  0.2034,  0.1225, -0.9414,  0.8160, -0.9966,\n",
       "          0.0146,  0.9848,  0.9078,  0.9369, -0.7724,  0.8304,  0.1551, -0.9929,\n",
       "         -0.1046,  0.9511,  0.4571,  0.9245, -0.9075,  0.5740,  0.1076,  0.2985,\n",
       "          0.9971, -0.9554,  0.6219, -0.9804,  0.1320, -0.1754,  0.4286,  0.0268,\n",
       "         -0.1651,  0.3251, -0.8883,  0.0446, -0.3614,  0.9599,  0.9952, -0.9978,\n",
       "         -0.9992, -0.7078,  0.9956, -0.2235, -0.9561, -0.0857, -0.2618,  0.9996,\n",
       "         -0.2522,  0.5867,  0.9970,  0.9991, -0.2247, -0.9975,  0.5941, -0.5111,\n",
       "         -0.9975,  0.1864,  0.9818,  0.9993, -0.1294, -0.2414,  0.2023, -0.1143,\n",
       "         -0.2062,  0.1635, -0.9876,  0.0130, -0.0694, -0.9983,  0.2742,  0.9567,\n",
       "          0.9649, -0.8356, -0.2645, -0.1113, -0.1519,  0.8304, -0.9543,  0.0964,\n",
       "         -0.4025,  0.0739, -0.8698, -0.2113, -0.9805, -0.3191,  0.8054,  0.0776,\n",
       "          0.6973,  0.0476, -0.0207, -0.8671, -0.9436,  0.3916, -0.1019, -0.9859,\n",
       "          0.0798, -0.9581, -0.9991, -0.9462, -0.1878, -0.9680,  0.1280,  0.2359,\n",
       "          0.0204,  0.3364,  0.0856,  0.9986,  0.9995,  0.9986,  0.0198,  0.9256,\n",
       "          0.9975,  0.9464,  0.4099, -0.0149, -0.9916, -0.9857,  0.0718, -0.3388,\n",
       "         -0.9371, -0.1467, -0.1604, -0.9999, -0.5067,  0.2304,  0.7520, -0.0376,\n",
       "          0.2220, -0.0184, -0.9999, -0.9926, -0.3871,  0.0390, -0.9823, -0.9970,\n",
       "          0.1571, -0.0396, -0.2149, -0.0874, -0.0310, -0.9140,  0.6648,  0.3655,\n",
       "         -0.1231,  0.0324,  0.9691,  0.9909,  0.2531, -1.0000,  0.1676,  0.9184,\n",
       "         -0.9964, -0.9579, -0.5313, -0.2015, -0.9995,  0.8767, -0.0735,  0.1782,\n",
       "         -0.1151,  0.2746, -0.9766, -0.5676, -0.2670,  0.9691, -0.6445, -0.1375,\n",
       "         -0.7184, -0.1460,  0.2923, -0.0894,  0.9013, -0.9996, -0.9186, -0.9250,\n",
       "          0.9908,  0.1496,  0.9234, -0.1879,  0.9119, -0.9986,  0.0016, -0.2271,\n",
       "         -0.8732, -0.0074,  0.9510, -0.9928, -0.4703,  0.3912,  0.9906,  0.5062,\n",
       "         -0.8596,  0.0101,  0.2661,  0.1418, -0.8638, -0.3049, -0.9899, -0.8850,\n",
       "          0.6825,  0.3599, -0.0198,  0.8243, -0.2023,  0.7691,  0.2454, -0.9992,\n",
       "          0.2349, -0.9925,  0.2967,  0.7507,  0.8211,  0.0341, -0.4270, -0.6599,\n",
       "         -0.3616,  0.2094,  0.0411,  0.2292, -0.0121,  0.1915,  0.9516,  0.9701,\n",
       "          0.2834, -0.9607, -0.1883, -0.9633, -0.3371, -0.2663, -0.0173, -0.1767,\n",
       "         -0.8341,  0.9669,  0.6909, -0.9870,  0.9849, -0.3145,  0.0296,  0.9638,\n",
       "          0.1802, -0.3676, -0.5336, -0.1902,  0.2289, -0.9831,  0.9874,  0.9219,\n",
       "         -0.3882, -0.9958, -0.9995, -0.9984,  0.0058, -0.9753, -0.0300,  0.2921,\n",
       "         -0.7111,  0.8655,  0.1294,  0.9939, -0.0202,  0.0837,  0.9840,  0.9970,\n",
       "         -0.9380, -0.4093,  0.2482, -0.7680, -0.2790,  0.3995, -0.2977, -0.8996,\n",
       "          0.0195,  0.0682, -0.0594,  0.1118, -0.2146, -0.5568, -0.1808,  0.0976,\n",
       "         -0.1124, -0.9774,  0.0718, -0.9703, -0.0393,  0.9841, -0.0989,  0.0271,\n",
       "         -0.9984,  0.9876, -0.3240,  0.2094,  0.2018,  0.9333,  0.9967,  0.0670,\n",
       "          0.1221, -0.1743, -0.9978,  0.9998, -0.9970, -0.2924, -0.1205,  0.8929,\n",
       "          0.0807, -0.5288,  0.1099,  0.9995,  0.1543, -0.3081,  0.0301, -0.1052,\n",
       "         -0.9997,  0.1086,  0.3836, -0.7368,  0.5983, -0.9997,  0.9987, -0.9989,\n",
       "         -0.3975,  0.1383, -0.4400,  0.9998, -0.9986,  0.1696,  0.3518,  0.9994,\n",
       "          0.9999,  0.9372, -0.9947,  0.1840, -0.0038,  0.9438, -0.1126,  0.9924,\n",
       "          0.9995, -0.9830, -0.3978,  0.3478, -0.9967, -0.9108,  0.0185,  0.9792,\n",
       "         -1.0000, -0.9202,  0.2843,  0.2503,  0.5255,  0.2320,  0.4980, -0.8176,\n",
       "         -0.9994, -0.7194, -0.9207, -0.9857,  0.0474,  0.9735, -0.1128, -0.4701,\n",
       "          0.0350,  0.6956,  0.0340,  0.0501,  1.0000,  0.1690, -0.9999, -0.0086,\n",
       "         -0.9932, -0.9555,  0.0440,  0.3642, -0.4288, -0.1988,  0.9998,  0.2795,\n",
       "         -0.0728, -0.2689, -0.1116, -0.1189,  0.0861, -0.9804, -0.7119, -0.9985,\n",
       "          0.1533, -0.1237, -0.4136, -0.2891, -0.2407, -0.9887,  0.3127,  0.1783],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor(9606))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_entry = {key: torch.tensor([value]) for key, value in dict(stonkgs_data.iloc[0]).items()}\n",
    "dummy_stonkgs_example = (stonkgs(**data_entry, return_dict=True).pooler_output[0], torch.tensor(labels[0]))\n",
    "print(dummy_stonkgs_example[0].shape)\n",
    "dummy_stonkgs_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effcacd4",
   "metadata": {},
   "source": [
    "## 3. Get the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a7fd3",
   "metadata": {},
   "source": [
    "1. NLP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983ae6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_embeddings(list_of_indices):\n",
    "    \"\"\"Returns a list of (embedding_sequence, label) pairs.\"\"\"\n",
    "    all_embed_sequences = []\n",
    "    \n",
    "    for idx in list_of_indices:\n",
    "        nlp_evidence = tokenizer(sampled_df.iloc[idx][\"evidence\"], return_tensors=\"pt\", padding='max_length', truncation=True)\n",
    "        nlp_hidden_states = (nlp_baseline(**nlp_evidence, output_hidden_states=True).pooler_output[0],\n",
    "                             torch.tensor(sampled_df.iloc[idx][\"class\"]))\n",
    "        all_embed_sequences.append(nlp_hidden_states)\n",
    "        \n",
    "    return all_embed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4de22f",
   "metadata": {},
   "source": [
    "2. KG embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857b4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kg_embeddings(list_of_indices):\n",
    "    \"\"\"Returns a list of (embedding_sequence, label) pairs.\"\"\"\n",
    "    all_embed_sequences = []\n",
    "    \n",
    "    for idx in list_of_indices:\n",
    "        all_embed_sequences.append((torch.max(kg_baseline[idx][0], dim=0).values, kg_baseline[idx][1]))\n",
    "        \n",
    "    return all_embed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637c0cc",
   "metadata": {},
   "source": [
    "3. STonKGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80eee495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stonkgs_embeddings(list_of_indices):\n",
    "    \"\"\"Returns a list of (embedding_sequence, label) pairs.\"\"\"\n",
    "    all_embed_sequences = []\n",
    "    \n",
    "    for idx in list_of_indices:\n",
    "        data_entry = {key: torch.tensor([value]) for key, value in dict(stonkgs_data.iloc[idx]).items()}\n",
    "        stonkgs_hidden_states = (stonkgs(**data_entry, return_dict=True).pooler_output[0],\n",
    "                                 torch.tensor(sampled_df.iloc[idx][\"class\"]))\n",
    "        all_embed_sequences.append(stonkgs_hidden_states)\n",
    "        \n",
    "    return all_embed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c475b",
   "metadata": {},
   "source": [
    "Testing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a7e421e",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.8199, 1.0339, 1.2151, 1.1758, 1.2501, 1.5135, 1.1532, 0.9345, 1.1966,\n",
       "          0.7390, 1.4022, 1.2629, 1.1392, 1.0948, 0.8903, 1.1800, 0.6760, 1.3727,\n",
       "          1.0618, 1.1497, 1.1216, 0.9651, 1.0477, 0.9641, 1.6039, 1.2026, 1.4565,\n",
       "          0.6601, 1.0177, 0.9012, 1.1241, 0.8775, 1.3370, 0.7827, 0.9532, 1.3188,\n",
       "          1.5685, 1.1096, 1.1083, 1.4297, 1.7709, 1.5323, 1.5550, 1.0358, 1.8667,\n",
       "          1.3972, 1.4358, 1.2755, 1.0149, 1.3661, 0.9928, 1.0757, 1.0334, 1.2195,\n",
       "          1.3659, 0.9006, 1.6616, 1.3232, 1.4256, 1.4424, 1.2029, 1.7379, 1.2585,\n",
       "          0.8998, 0.8873, 1.4440, 1.0620, 1.1747, 1.1599, 1.3955, 1.5962, 0.8583,\n",
       "          1.3953, 1.7699, 1.6168, 1.0860, 1.2218, 1.3588, 1.3704, 1.1862, 1.8271,\n",
       "          1.1568, 1.2779, 1.9205, 0.8217, 1.3620, 1.4497, 1.2661, 0.8700, 1.2905,\n",
       "          3.4755, 0.9639, 1.5833, 1.4184, 0.8765, 0.8023, 1.2879, 1.3099, 1.5188,\n",
       "          1.7380, 1.1449, 0.8658, 0.7098, 1.5686, 0.8454, 1.0747, 0.9146, 1.4942,\n",
       "          1.1165, 0.9294, 1.0097, 1.0930, 1.3517, 0.8319, 1.6811, 1.0967, 1.6163,\n",
       "          0.9998, 1.6463, 1.3047, 1.1263, 1.3402, 1.1856, 1.4273, 1.2592, 1.4369,\n",
       "          1.0602, 1.3700, 0.9432, 1.4340, 1.4559, 1.0907, 0.9351, 1.0442, 1.6811,\n",
       "          1.0013, 1.1559, 0.9847, 1.3050, 0.9371, 1.4576, 1.0785, 1.8349, 0.8347,\n",
       "          1.2599, 0.6848, 1.4117, 1.1568, 1.5676, 2.1265, 1.2191, 0.8650, 1.6809,\n",
       "          1.0337, 1.0631, 0.8905, 1.1024, 1.2606, 1.8901, 1.5279, 1.6770, 1.1705,\n",
       "          0.9023, 1.5467, 1.0235, 1.0330, 1.9220, 1.3781, 1.4992, 0.9316, 1.2705,\n",
       "          1.0720, 1.2385, 1.2937, 1.3496, 1.0137, 0.9301, 1.2753, 1.2439, 0.9455,\n",
       "          1.3373, 1.3018, 1.2028, 2.0179, 1.4964, 1.1584, 1.2055, 0.9999, 0.8831,\n",
       "          0.9206, 0.9540, 1.4265, 0.6875, 0.8960, 1.0802, 1.1233, 0.5590, 0.8251,\n",
       "          1.0972, 1.2157, 1.4524, 1.5506, 0.8599, 0.7488, 1.1648, 1.1859, 1.8407,\n",
       "          1.3040, 1.2924, 1.3314, 1.4024, 1.0840, 1.2022, 1.0738, 1.1887, 1.2629,\n",
       "          1.0554, 1.7768, 1.0459, 0.9331, 1.2353, 1.1828, 0.9238, 1.4456, 1.4102,\n",
       "          1.4018, 1.5897, 0.6548, 0.9762, 1.2898, 1.7981, 1.1626, 1.0370, 1.6420,\n",
       "          0.9203, 1.3529, 1.1245, 0.7730, 0.9038, 0.7553, 0.8711, 1.3018, 1.1265,\n",
       "          0.9592, 0.8837, 1.2727, 1.4411, 1.2953, 1.1185, 1.6910, 0.7492, 1.0791,\n",
       "          0.9859, 1.7367, 1.2414, 1.3786, 0.8418, 1.8992, 0.7364, 1.1543, 1.0365,\n",
       "          1.0389, 1.0829, 1.0290, 1.4751, 1.2998, 1.1790, 1.5383, 1.1729, 0.7727,\n",
       "          1.1167, 1.6407, 1.1619, 0.7831, 0.8656, 1.7207, 1.2841, 1.1737, 1.1878,\n",
       "          1.0864, 1.7593, 1.3773, 0.8574, 0.9937, 1.1617, 1.2262, 1.0795, 1.2038,\n",
       "          1.9876, 1.6055, 0.7528, 0.9520, 1.0356, 0.7565, 1.5880, 1.9344, 1.0131,\n",
       "          1.1697, 1.5675, 1.2841, 0.9851, 1.2771, 1.3393, 1.1556, 1.0825, 1.6013,\n",
       "          0.9701, 1.0722, 0.9636, 1.8663, 0.6815, 0.9046, 0.8637, 0.9442, 1.6469,\n",
       "          1.1381, 1.5878, 1.1226, 1.1566, 1.3512, 0.9265, 1.1838, 2.0952, 1.3213,\n",
       "          0.7646, 2.3812, 1.1324, 1.0676, 1.7695, 1.2582, 1.1491, 1.5028, 1.0868,\n",
       "          0.9054, 0.8581, 1.0571, 0.8867, 0.9734, 1.1622, 1.4391, 1.1212, 1.1264,\n",
       "          1.2416, 0.9929, 1.9614, 1.6835, 1.2615, 1.7253, 0.7416, 0.6001, 1.4125,\n",
       "          1.4535, 1.5234, 1.2105, 1.0111, 0.9602, 1.1301, 1.1660, 0.9910, 0.9812,\n",
       "          0.9486, 1.1717, 1.1869, 1.1642, 1.9035, 1.5366, 0.8140, 1.0532, 0.9094,\n",
       "          1.0091, 0.8849, 1.1952, 1.7093, 1.1142, 1.2986, 1.1192, 0.9063, 1.1690,\n",
       "          1.0332, 1.0981, 0.9471, 0.9337, 1.1611, 0.6811, 1.0357, 0.9022, 1.9804,\n",
       "          1.3051, 1.3701, 0.8646, 1.3120, 1.2847, 0.7533, 0.9793, 1.3340, 1.3542,\n",
       "          0.7859, 2.1534, 1.3190, 1.2715, 0.9752, 1.3575, 1.0791, 0.7036, 0.5098,\n",
       "          1.1546, 0.9092, 1.2502, 1.3746, 1.5670, 1.6872, 0.9092, 1.6133, 0.9383,\n",
       "          1.1864, 0.8810, 1.0951, 1.3115, 1.0117, 1.1603, 1.1021, 1.7194, 1.1284,\n",
       "          1.0685, 2.2912, 0.9703, 1.2665, 4.4291, 1.2646, 1.0757, 1.4685, 1.5619,\n",
       "          1.1413, 0.8295, 0.7952, 2.4972, 1.0401, 1.0434, 1.1534, 0.9534, 2.6844,\n",
       "          0.9529, 0.6877, 0.8219, 0.9577, 0.8741, 1.1531, 0.8902, 1.2745, 1.6468,\n",
       "          0.9198, 0.9225, 1.4570, 1.1823, 1.0003, 1.4795, 1.5745, 1.2115, 1.5418,\n",
       "          1.1858, 1.0792, 0.9986, 1.1360, 0.9616, 1.8301, 1.2620, 1.3445, 1.1561,\n",
       "          1.1543, 1.2174, 1.1470, 1.0301, 0.8142, 0.8957, 0.9275, 1.2361, 1.0688,\n",
       "          0.6375, 1.0938, 0.7172, 1.0419, 1.1710, 0.8201, 0.9225, 1.3880, 0.8494,\n",
       "          0.9186, 1.3894, 0.9275, 1.9200, 1.0601, 0.7190, 0.9311, 1.3456, 1.3554,\n",
       "          1.8411, 0.9758, 0.8449, 0.9805, 1.5280, 1.5541, 1.1374, 0.9974, 1.7006,\n",
       "          1.7698, 1.8909, 2.0968, 2.7512, 1.4570, 1.1059, 1.5627, 1.4730, 1.3024,\n",
       "          0.9867, 1.1480, 0.8998, 1.3606, 1.4906, 1.1241, 0.9269, 1.3208, 1.1886,\n",
       "          0.9321, 1.2318, 0.9960, 0.9496, 0.9512, 1.2439, 1.7278, 1.0046, 1.1339,\n",
       "          1.7017, 1.7528, 1.6058, 1.1515, 1.3957, 1.1480, 1.5278, 1.1721, 1.3165,\n",
       "          1.0307, 1.4516, 1.1039, 0.8209, 1.2724, 1.0104, 1.0527, 1.1585, 1.0810,\n",
       "          1.7639, 0.9947, 0.9377, 0.9494, 0.9281, 1.4526, 1.3141, 1.6449, 1.0157,\n",
       "          1.0302, 1.2297, 1.1819, 1.1632, 1.0570, 1.1343, 1.2098, 1.2113, 1.3713,\n",
       "          0.7795, 1.4598, 1.5445, 0.9491, 1.2938, 0.7905, 1.1871, 0.6603, 1.4778,\n",
       "          1.0729, 2.3251, 0.9866, 1.4689, 1.2389, 1.5522, 0.8481, 1.1947, 1.6798,\n",
       "          1.0635, 1.5590, 1.1421, 1.2287, 1.5759, 1.0800, 1.1464, 0.9939, 1.1409,\n",
       "          1.6905, 0.8706, 1.1734, 0.8155, 1.3887, 1.0165, 0.9384, 1.4595, 1.0920,\n",
       "          1.2141, 1.5911, 0.9613, 0.6903, 1.7197, 0.7628, 1.3914, 1.4989, 0.9624,\n",
       "          1.4675, 1.3390, 1.0667, 1.1978, 1.2085, 0.9755, 1.0457, 1.1942, 1.3508,\n",
       "          0.8996, 0.9973, 1.4872, 1.1210, 1.6558, 1.3963, 1.0604, 1.2900, 0.8449,\n",
       "          0.7781, 1.1679, 0.9352, 1.0129, 1.6344, 1.5367, 0.7670, 0.6341, 1.3952,\n",
       "          1.2570, 1.5668, 1.0990, 1.8290, 0.9580, 1.6031, 1.1468, 1.4535, 1.1803,\n",
       "          1.6475, 1.2613, 0.9316, 1.5793, 1.0595, 1.4383, 1.3465, 1.6316, 1.6850,\n",
       "          0.9020, 1.0123, 1.6293, 1.0662, 1.6527, 1.1159, 0.8755, 1.0080, 0.7219,\n",
       "          1.5963, 1.3225, 0.7321, 1.1418, 1.0338, 1.1236, 0.9426, 1.4737, 1.1344,\n",
       "          1.1368, 1.0534, 1.1205, 1.1622, 1.6003, 1.1861, 0.9999, 1.1614, 0.6948,\n",
       "          1.1719, 1.5578, 1.4656, 1.5380, 1.1302, 0.7618, 1.3166, 1.7598, 1.0246,\n",
       "          1.3416, 1.8350, 1.2565, 1.5515, 1.3137, 1.0938, 0.8372, 0.8076, 1.4977,\n",
       "          1.2528, 1.0791, 1.0453, 1.2270, 1.6380, 0.9622, 1.4782, 1.8822, 1.9411,\n",
       "          1.1756, 1.2871, 1.2548, 1.9732, 1.1390, 1.0707, 0.8964, 1.4969, 0.9451,\n",
       "          1.1631, 1.6267, 1.4972, 1.3460, 1.4333, 2.0004, 1.8725, 1.0905, 1.6644,\n",
       "          0.9316, 2.4677, 1.2370, 1.0472, 1.4800, 2.0600, 1.0768, 1.3842, 0.6593,\n",
       "          1.4174, 1.6254, 2.1656, 1.0960, 1.3515, 1.2660, 0.7044, 1.4353, 1.3284,\n",
       "          1.1250, 1.3180, 0.9900, 1.0089, 1.3809, 1.6532, 0.9847, 0.9875, 1.5487,\n",
       "          1.1135, 1.2585, 0.8239, 1.3912, 1.4812, 0.9173, 1.3467, 1.1790, 1.0983,\n",
       "          2.1196, 1.0972, 1.0002]),\n",
       "  tensor(9606)),\n",
       " (tensor([0.8886, 1.0236, 0.9865, 1.4803, 1.3703, 1.5135, 1.3103, 1.0291, 0.9154,\n",
       "          1.4188, 1.4019, 1.2950, 1.0676, 1.1607, 1.1547, 1.1800, 0.8374, 1.1620,\n",
       "          1.0798, 1.1579, 1.3912, 1.2672, 1.0122, 1.2151, 1.7806, 1.2026, 1.4565,\n",
       "          0.9151, 1.0917, 0.8406, 0.9629, 1.3739, 1.5535, 0.7040, 0.8661, 0.7862,\n",
       "          1.0458, 0.9875, 0.8134, 1.2707, 1.4221, 1.5359, 1.5550, 0.8087, 1.7208,\n",
       "          1.3972, 1.4999, 0.8973, 1.0198, 1.3701, 0.7517, 0.9606, 0.9817, 1.7644,\n",
       "          0.7354, 0.7981, 1.6057, 1.3929, 1.4256, 1.4424, 1.2029, 1.7379, 1.2922,\n",
       "          0.9549, 0.8536, 0.9972, 0.9465, 1.2729, 1.1599, 1.0142, 1.5962, 1.0911,\n",
       "          1.3953, 0.7456, 1.6168, 1.1508, 1.2218, 1.3588, 0.8057, 0.7087, 1.6423,\n",
       "          1.1528, 1.2779, 1.5171, 1.3136, 1.4454, 0.9238, 0.8553, 1.0984, 1.2961,\n",
       "          1.6188, 0.7731, 1.5680, 1.4184, 0.8646, 0.7760, 1.0217, 1.4207, 1.5188,\n",
       "          0.5750, 1.1124, 0.6766, 0.8322, 1.5686, 1.2160, 0.9969, 1.0549, 1.1281,\n",
       "          0.9888, 0.7905, 0.9130, 1.4531, 1.3517, 0.8485, 1.4900, 1.1727, 0.8049,\n",
       "          1.2884, 1.3611, 1.1876, 1.0622, 1.6282, 1.1975, 1.4273, 1.4644, 1.0025,\n",
       "          1.3753, 1.4266, 0.8736, 1.6203, 1.1267, 1.1215, 0.9073, 1.3433, 1.6811,\n",
       "          1.0266, 0.9525, 1.0801, 1.1172, 1.8125, 1.2707, 1.1089, 1.3612, 1.5549,\n",
       "          1.3311, 0.5386, 1.0632, 1.2299, 1.3605, 1.8542, 1.1833, 0.7079, 1.2642,\n",
       "          1.0192, 0.7866, 1.0184, 1.0313, 1.0684, 1.4768, 1.6831, 1.6770, 1.0366,\n",
       "          0.9608, 1.5410, 1.2328, 0.7714, 2.0628, 1.3781, 1.1804, 1.0831, 1.2900,\n",
       "          1.3011, 0.8827, 0.7433, 0.8596, 1.5185, 1.0632, 0.9529, 1.1764, 1.0616,\n",
       "          0.9533, 1.3018, 1.2197, 2.0179, 1.0086, 1.1617, 1.0414, 1.9866, 0.7748,\n",
       "          1.3031, 1.0515, 1.1832, 0.6269, 0.9173, 1.1931, 1.1631, 0.8750, 1.0620,\n",
       "          0.6940, 1.1605, 1.3624, 1.5506, 0.8324, 0.6932, 1.0866, 1.2101, 1.5244,\n",
       "          1.0521, 1.3726, 1.3255, 1.2641, 1.0323, 1.2022, 0.9642, 0.6666, 1.1949,\n",
       "          0.7537, 1.0646, 1.3110, 0.7969, 1.2676, 1.1719, 1.3632, 1.2396, 2.3535,\n",
       "          1.4018, 1.5897, 1.1745, 1.2871, 1.0846, 2.3934, 1.3274, 1.3319, 1.1941,\n",
       "          0.8487, 0.9673, 0.6883, 0.8503, 1.0775, 0.7522, 0.7900, 1.2080, 1.1265,\n",
       "          1.2399, 1.1597, 0.7179, 1.1586, 1.1265, 0.9340, 1.6910, 0.8534, 1.1176,\n",
       "          1.0191, 1.1793, 1.2269, 1.0782, 0.9479, 1.8233, 0.7389, 1.3434, 1.3271,\n",
       "          1.1565, 0.8999, 0.9139, 1.4751, 1.3689, 0.7860, 1.2473, 1.0449, 0.9580,\n",
       "          1.0480, 1.7853, 1.0453, 0.9161, 0.7994, 1.5822, 0.8748, 1.3508, 1.1733,\n",
       "          1.0745, 1.5796, 1.1212, 1.1165, 1.0514, 1.0038, 1.2278, 0.8949, 1.0141,\n",
       "          1.8256, 1.8161, 0.8788, 1.2697, 0.9657, 0.7565, 1.6330, 1.9238, 0.8121,\n",
       "          1.3188, 1.5675, 1.2816, 0.9918, 1.2771, 1.3454, 1.0210, 1.2001, 1.1070,\n",
       "          1.0793, 1.1789, 0.8889, 1.7509, 0.6234, 0.8161, 0.8554, 0.9069, 1.6186,\n",
       "          0.9863, 1.4894, 0.7200, 1.1566, 1.2588, 0.8648, 1.1937, 1.7366, 1.2691,\n",
       "          0.7709, 2.3812, 1.3245, 1.3941, 1.7695, 1.2068, 1.1491, 1.2744, 1.5709,\n",
       "          0.8371, 0.8090, 1.2856, 0.9435, 1.2238, 1.2197, 1.2531, 1.1113, 1.0114,\n",
       "          0.8767, 0.8136, 1.9614, 1.5531, 1.1051, 1.7507, 0.6293, 0.7533, 1.5479,\n",
       "          1.4330, 1.5234, 1.2105, 1.0111, 1.0196, 1.0997, 1.1086, 0.9694, 1.3270,\n",
       "          0.7289, 1.1481, 1.2756, 1.1642, 1.9035, 1.5366, 0.8635, 1.0508, 1.1006,\n",
       "          1.2915, 0.8128, 1.0795, 1.2263, 1.2787, 1.2865, 1.1192, 0.9533, 0.8687,\n",
       "          0.7872, 0.9088, 1.1977, 0.9455, 0.8698, 1.0818, 1.2200, 0.8215, 1.9255,\n",
       "          1.3051, 1.4760, 0.8829, 0.9258, 1.2794, 0.5477, 0.9413, 0.9612, 1.3542,\n",
       "          0.8111, 1.6611, 1.2907, 1.2204, 1.1657, 1.3575, 0.9529, 0.4635, 0.6744,\n",
       "          0.8493, 1.0441, 1.3600, 1.6471, 1.5670, 1.3595, 0.7753, 1.6133, 1.0339,\n",
       "          1.0075, 1.1806, 0.7967, 1.7633, 1.0784, 0.7235, 1.1201, 1.3876, 1.1224,\n",
       "          1.1945, 1.9559, 0.9249, 1.8603, 3.5165, 1.2646, 1.3295, 1.4685, 1.4219,\n",
       "          1.3568, 1.0821, 0.7792, 1.6653, 1.1326, 1.0434, 1.1840, 1.4487, 1.5234,\n",
       "          1.2264, 0.7412, 0.5788, 0.9297, 1.0757, 1.0725, 0.9181, 1.3791, 1.2247,\n",
       "          0.8271, 1.1072, 1.5644, 1.8085, 1.4691, 0.8243, 1.4939, 1.1860, 1.5041,\n",
       "          1.6498, 1.0246, 0.9435, 1.3414, 1.2787, 1.6933, 1.2092, 1.1177, 1.2336,\n",
       "          1.0082, 1.2120, 1.3087, 0.9285, 1.0031, 1.5469, 0.9418, 1.2361, 1.1243,\n",
       "          0.9587, 0.8320, 0.7409, 1.2293, 0.8984, 0.9031, 0.8957, 1.2800, 0.9585,\n",
       "          0.8330, 1.2811, 0.8594, 1.7771, 1.0392, 0.8604, 1.1161, 1.0377, 1.2552,\n",
       "          1.8411, 0.9091, 0.8211, 1.1155, 1.1077, 1.6723, 1.1374, 1.1550, 1.1815,\n",
       "          1.1374, 1.3109, 1.7884, 1.7895, 1.3290, 1.0744, 1.3644, 1.1236, 1.3034,\n",
       "          0.9975, 1.1480, 0.9375, 1.1134, 1.1230, 1.1241, 0.9247, 1.4527, 0.6374,\n",
       "          0.9104, 1.2318, 1.0210, 0.8264, 0.7500, 0.9135, 1.0936, 1.0221, 1.4005,\n",
       "          1.1755, 1.5111, 1.3876, 1.3875, 0.9125, 0.8109, 1.0593, 1.2911, 1.6053,\n",
       "          0.9901, 1.4516, 1.1664, 1.0416, 1.2610, 1.0097, 1.1246, 0.9471, 1.0810,\n",
       "          1.7467, 0.9910, 0.9178, 1.0157, 0.9950, 0.9533, 1.7629, 1.9421, 1.2146,\n",
       "          1.0302, 3.3097, 1.2137, 1.1632, 0.6606, 0.8947, 0.8986, 1.3562, 1.2867,\n",
       "          0.9641, 1.1610, 1.3043, 0.9935, 1.1996, 0.8344, 1.5492, 1.0637, 0.9591,\n",
       "          0.9480, 1.0897, 0.9866, 0.9223, 1.1362, 1.2471, 1.4503, 1.1187, 0.8792,\n",
       "          1.1602, 1.5590, 1.1421, 1.0123, 1.2381, 1.3418, 1.1720, 0.9785, 1.0175,\n",
       "          1.7382, 0.9234, 1.1734, 0.8439, 1.1714, 0.8866, 0.6638, 1.4595, 1.0138,\n",
       "          1.2425, 1.5811, 0.8003, 0.9066, 1.1417, 1.0766, 1.0700, 0.6539, 0.6685,\n",
       "          1.2491, 1.0709, 0.8094, 1.6232, 0.8702, 1.0581, 0.7540, 1.1526, 1.4638,\n",
       "          0.9827, 1.0104, 1.3526, 1.1050, 1.6558, 1.3963, 1.1246, 1.3241, 1.1519,\n",
       "          0.9012, 1.2584, 0.8907, 0.8161, 1.4814, 1.5367, 0.6292, 0.8190, 1.3349,\n",
       "          1.0498, 1.2629, 0.8589, 1.8290, 1.0944, 1.6031, 1.1151, 1.4535, 1.2536,\n",
       "          1.5439, 1.5535, 1.1727, 1.3513, 1.0174, 1.7947, 1.3784, 1.6316, 1.6850,\n",
       "          1.1885, 0.7481, 1.9394, 1.0211, 1.4396, 1.0251, 1.0587, 0.9394, 1.0434,\n",
       "          1.6190, 1.4490, 0.8073, 1.5400, 1.0338, 1.1283, 1.1855, 1.4031, 0.9819,\n",
       "          1.3732, 1.2198, 0.8169, 1.1622, 2.2506, 1.1162, 1.2920, 0.5421, 1.0467,\n",
       "          1.2716, 1.4389, 1.2729, 1.2344, 1.3236, 0.8033, 1.3166, 1.2950, 1.0927,\n",
       "          1.5150, 1.3821, 1.2166, 1.5969, 1.4341, 1.3338, 0.9600, 1.0326, 1.6224,\n",
       "          1.0791, 1.0047, 0.8605, 1.1936, 2.1161, 0.9710, 2.2357, 1.8822, 2.2055,\n",
       "          1.3861, 1.8505, 0.9645, 1.9732, 1.6446, 0.8945, 0.9922, 1.0676, 1.3315,\n",
       "          0.8647, 1.6267, 1.3958, 1.2949, 1.3741, 2.8014, 1.4346, 1.9014, 3.2412,\n",
       "          0.9655, 3.3664, 1.3339, 1.0472, 1.2021, 4.6874, 0.9388, 1.1385, 0.7012,\n",
       "          1.4174, 1.8672, 1.8140, 0.7085, 1.2429, 1.2082, 1.0181, 1.0443, 1.1310,\n",
       "          1.2648, 1.1494, 1.2437, 0.9941, 1.6656, 1.6532, 0.7486, 1.7093, 1.2725,\n",
       "          1.3005, 0.9468, 1.0830, 1.0962, 1.2826, 1.0219, 1.2502, 0.7851, 1.1236,\n",
       "          1.4771, 1.2473, 0.7862]),\n",
       "  tensor(9606)),\n",
       " (tensor([1.0409, 1.0339, 1.2743, 1.4357, 1.1869, 1.3450, 1.0725, 0.9236, 1.3741,\n",
       "          0.7390, 1.4022, 1.2950, 1.1392, 1.0910, 0.8903, 1.1800, 1.2709, 1.0627,\n",
       "          1.0618, 1.1120, 1.1216, 0.9540, 1.2322, 0.9641, 1.7806, 1.4221, 1.4565,\n",
       "          0.6601, 1.1651, 0.8406, 1.1299, 1.3739, 1.5535, 0.6819, 0.9532, 0.9485,\n",
       "          1.5685, 1.1096, 1.1083, 1.3883, 1.3110, 1.2274, 1.5550, 1.0358, 1.4149,\n",
       "          1.3972, 1.4115, 1.2335, 1.0149, 1.3701, 0.8093, 1.0757, 1.1485, 0.9170,\n",
       "          1.3659, 0.9006, 1.6616, 1.3232, 1.2176, 1.4424, 1.2029, 1.7379, 1.2427,\n",
       "          0.8998, 0.8873, 1.4440, 1.0620, 1.2800, 1.0967, 0.7614, 1.5962, 0.8583,\n",
       "          1.1312, 1.7699, 1.6168, 1.1710, 1.1418, 1.3323, 1.3704, 0.7957, 1.8271,\n",
       "          0.9627, 1.2779, 1.9205, 0.7989, 1.3489, 1.4497, 1.2661, 1.0984, 1.3138,\n",
       "          3.4755, 0.9639, 1.5833, 1.4184, 0.7771, 0.9661, 1.2879, 1.3619, 1.5188,\n",
       "          1.7380, 0.9676, 0.8658, 0.7098, 1.5686, 1.0557, 1.3200, 0.7376, 1.1148,\n",
       "          1.1165, 0.9294, 1.0097, 1.0136, 1.4516, 0.8319, 1.4074, 1.0967, 1.6163,\n",
       "          0.9998, 1.2705, 1.3047, 0.8703, 1.9261, 1.1975, 1.4273, 1.2933, 1.4369,\n",
       "          1.2500, 1.3700, 1.0366, 1.2989, 1.4559, 1.0907, 0.9351, 1.0132, 1.6811,\n",
       "          1.0266, 0.9416, 0.9954, 1.1450, 0.9371, 1.2707, 1.0785, 1.8349, 1.0607,\n",
       "          1.2599, 0.4287, 1.4117, 1.1568, 1.5676, 2.2890, 1.4287, 0.9621, 1.6809,\n",
       "          1.1285, 1.0631, 1.1180, 1.1024, 1.2606, 1.6667, 1.1893, 1.6770, 1.1705,\n",
       "          0.9562, 1.5467, 1.0235, 0.9659, 2.0871, 1.4512, 1.4992, 0.8760, 1.2705,\n",
       "          1.0720, 1.2385, 1.2937, 1.3496, 1.2073, 0.9301, 1.0112, 1.2439, 0.9455,\n",
       "          1.3373, 1.3018, 1.0518, 2.0179, 1.4197, 1.0565, 1.2055, 0.9999, 0.9824,\n",
       "          0.9206, 1.0512, 1.4265, 0.6875, 0.8960, 0.7649, 1.1233, 0.5994, 0.6836,\n",
       "          0.9733, 1.3605, 1.4524, 0.8658, 0.8599, 0.7488, 1.1648, 1.4918, 1.8407,\n",
       "          1.0880, 1.2924, 1.3314, 1.4024, 1.0840, 0.9919, 0.9742, 1.1887, 1.1901,\n",
       "          1.0554, 0.9956, 1.2970, 0.5049, 1.2353, 1.1828, 0.9511, 1.4456, 2.3535,\n",
       "          1.4018, 1.5897, 0.6591, 1.2871, 1.0696, 2.3934, 1.1626, 1.0394, 1.0372,\n",
       "          0.9203, 0.9895, 0.9432, 1.1271, 1.0394, 0.6968, 0.8006, 1.3018, 0.9543,\n",
       "          0.9592, 0.8008, 1.2523, 1.4411, 1.2953, 1.0184, 1.6910, 0.7492, 1.0028,\n",
       "          0.7821, 1.7367, 1.2414, 1.3891, 0.8598, 1.8992, 0.7389, 1.3147, 1.0365,\n",
       "          1.0389, 0.8644, 1.2371, 1.4751, 1.2998, 1.1790, 1.1937, 0.5605, 0.5394,\n",
       "          1.3966, 1.6407, 1.0190, 0.9161, 0.8656, 1.5822, 1.2841, 1.3508, 1.4395,\n",
       "          1.0864, 1.7593, 1.4256, 0.8574, 0.8736, 1.1617, 1.2262, 1.1139, 1.2038,\n",
       "          1.9876, 2.4668, 0.7528, 1.1421, 0.8914, 0.7565, 1.6771, 2.1661, 1.0131,\n",
       "          1.5014, 1.5675, 1.8643, 0.9918, 1.2771, 1.3393, 1.3613, 1.0825, 1.1380,\n",
       "          1.0793, 1.0722, 1.0225, 1.8663, 0.6586, 0.9046, 0.7646, 0.8336, 1.6366,\n",
       "          1.1381, 1.4841, 1.1226, 1.1566, 1.3512, 0.8996, 1.2561, 2.0952, 1.3213,\n",
       "          0.7987, 2.3812, 1.1324, 1.3941, 1.7695, 1.2582, 1.1491, 1.5028, 1.0868,\n",
       "          0.8371, 0.8581, 1.0571, 0.8733, 0.8144, 1.2793, 1.4391, 1.3944, 1.1264,\n",
       "          1.2416, 0.9929, 1.9614, 1.3336, 1.2615, 1.5862, 0.7416, 0.9665, 1.4125,\n",
       "          1.4535, 1.5234, 1.2105, 1.0303, 1.5137, 1.1301, 1.1660, 0.9910, 1.0945,\n",
       "          0.9486, 1.0970, 1.2049, 1.1642, 1.8942, 1.5366, 0.8140, 1.0532, 0.8311,\n",
       "          1.3336, 0.9466, 1.1952, 1.7093, 1.1142, 1.2986, 1.2571, 0.9063, 0.7860,\n",
       "          1.0332, 1.0981, 0.9471, 0.6820, 1.0578, 0.6811, 1.1070, 0.8365, 1.9255,\n",
       "          1.3051, 1.3701, 0.8934, 1.2162, 1.1984, 0.7533, 1.0768, 1.3340, 1.3542,\n",
       "          0.9900, 1.6611, 1.0941, 1.6217, 1.1657, 1.3575, 1.4625, 0.7036, 0.6726,\n",
       "          1.1546, 0.9092, 1.3678, 1.3570, 1.5756, 0.9606, 0.5967, 1.3705, 1.0816,\n",
       "          1.1864, 0.8810, 1.0951, 1.5756, 1.0117, 0.9247, 1.1047, 1.7194, 1.1284,\n",
       "          0.9162, 2.2912, 0.9703, 1.0818, 4.4291, 1.2646, 1.2289, 1.4685, 1.5619,\n",
       "          1.0375, 0.8914, 1.0555, 2.4972, 1.0401, 0.8885, 1.1534, 1.0437, 2.6844,\n",
       "          0.9529, 0.9516, 0.8219, 1.1642, 1.1854, 1.1456, 0.8902, 1.4812, 1.6468,\n",
       "          0.9198, 0.7921, 1.4570, 1.2823, 1.0793, 1.1406, 1.5745, 1.2115, 1.5418,\n",
       "          1.1757, 1.0777, 0.9986, 0.9095, 0.8069, 1.2183, 1.2263, 1.2400, 1.2496,\n",
       "          1.1543, 1.2120, 1.1470, 1.0301, 0.8142, 0.8322, 1.7670, 1.2361, 1.4525,\n",
       "          0.7454, 1.0938, 1.1831, 1.2293, 1.0791, 0.8201, 0.9225, 1.3880, 0.8494,\n",
       "          0.9186, 1.3894, 1.0243, 1.9200, 1.0555, 1.0397, 0.9321, 1.3456, 1.2552,\n",
       "          1.8411, 0.8112, 1.0304, 0.9790, 1.1570, 1.5541, 1.2147, 1.0544, 2.0050,\n",
       "          1.4661, 1.3143, 1.5378, 1.5393, 1.4570, 1.0750, 1.4801, 1.4730, 1.3024,\n",
       "          0.7852, 1.1480, 0.8998, 1.1535, 1.6406, 0.8803, 0.9269, 1.2367, 0.7409,\n",
       "          0.9321, 1.2318, 0.9960, 1.0795, 0.8798, 0.8694, 1.7278, 1.0046, 0.8437,\n",
       "          1.7017, 1.7528, 1.6058, 1.3377, 0.7976, 0.8761, 1.5278, 1.1962, 1.3455,\n",
       "          1.0307, 1.4516, 1.2283, 0.8209, 1.0892, 1.0104, 1.0527, 1.1722, 1.0810,\n",
       "          1.6463, 0.9947, 0.9242, 0.9494, 0.9281, 1.4526, 1.3141, 1.6449, 1.0157,\n",
       "          1.0302, 1.2297, 1.0750, 1.1632, 1.0570, 1.1163, 1.2098, 1.2247, 1.3872,\n",
       "          0.7795, 1.4598, 1.2777, 0.9491, 1.2938, 0.8640, 1.1871, 0.9151, 1.4778,\n",
       "          0.8909, 1.4124, 0.9778, 1.4689, 1.2796, 1.5522, 1.0813, 1.1670, 1.3447,\n",
       "          1.1602, 1.5590, 1.1421, 1.2287, 1.1065, 1.0800, 1.1464, 0.9939, 1.3618,\n",
       "          1.6905, 0.8707, 1.1734, 1.0855, 1.3887, 0.8700, 0.7173, 1.4595, 1.0920,\n",
       "          1.2004, 1.5911, 0.6348, 0.8913, 1.2426, 0.9413, 1.3914, 1.4989, 0.9624,\n",
       "          1.2587, 1.3390, 1.0667, 1.3526, 1.2052, 0.6776, 0.9125, 1.1733, 1.0692,\n",
       "          0.8996, 0.9973, 1.1547, 1.2541, 1.6558, 1.3963, 1.0604, 1.2933, 0.8449,\n",
       "          0.7743, 1.3137, 0.9352, 1.0129, 1.6344, 1.5367, 0.7670, 0.6501, 1.0780,\n",
       "          1.4218, 1.5668, 1.0990, 1.8290, 1.0944, 1.6031, 1.1468, 1.4535, 1.0578,\n",
       "          1.6475, 1.4904, 0.9316, 1.5793, 1.0595, 1.4383, 1.3465, 1.6316, 1.6850,\n",
       "          0.7690, 0.9845, 1.4774, 1.1679, 1.6527, 1.2086, 1.0878, 1.0080, 0.5930,\n",
       "          1.5963, 1.3225, 1.0234, 1.2288, 1.1021, 0.8778, 0.8629, 1.4737, 1.1344,\n",
       "          1.4222, 1.0534, 1.1205, 1.1622, 0.9518, 1.1861, 0.7894, 1.1614, 0.6778,\n",
       "          1.2383, 1.5578, 1.4656, 1.5380, 1.3236, 0.7618, 1.5825, 1.7598, 1.0927,\n",
       "          1.3416, 1.8350, 1.2565, 1.5969, 1.3137, 1.3338, 0.7991, 1.0326, 1.4977,\n",
       "          1.2528, 0.8757, 0.7189, 1.1236, 2.1161, 0.9622, 2.2357, 1.8822, 2.2055,\n",
       "          1.7114, 2.0192, 1.2548, 1.9732, 0.9120, 1.0707, 0.8964, 1.0092, 1.0886,\n",
       "          1.9291, 0.9063, 1.4972, 2.2522, 1.4333, 2.8014, 1.4346, 1.9014, 3.2412,\n",
       "          0.9250, 3.3664, 1.2601, 1.1142, 1.4800, 4.6874, 1.0745, 1.3842, 0.6593,\n",
       "          1.4174, 1.8672, 2.1656, 0.8248, 1.3515, 1.2660, 1.0181, 1.4353, 0.9986,\n",
       "          0.9193, 1.3180, 0.9645, 0.9271, 1.3809, 1.6532, 0.8145, 1.3404, 1.6444,\n",
       "          1.1135, 1.0079, 0.8239, 0.9375, 1.4812, 1.0219, 1.2502, 1.1790, 1.0904,\n",
       "          1.4771, 1.0972, 0.8362]),\n",
       "  tensor(10116))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nlp_embeddings([1,5,15])\n",
    "get_kg_embeddings([105,150,400])\n",
    "get_kg_embeddings([50,20,600])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}